{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb37ea4-687d-44a1-9fa8-f0b22215880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the Earth Engine API (authentication required)\n",
    "# ee.Authenticate()\n",
    "# ee.Initialize()\n",
    "\n",
    "# List of cities with latitude and longitude\n",
    "cities = [\n",
    "    {\"name\": \"Vienna\", \"latitude\": 48.2082, \"longitude\": 16.3738},\n",
    "    {\"name\": \"Munich\", \"latitude\": 48.1351, \"longitude\": 11.5820},\n",
    "    {\"name\": \"New York\", \"latitude\": 40.7128, \"longitude\": -74.0060},\n",
    "    {\"name\": \"Dubai\", \"latitude\": 25.276987, \"longitude\": 55.296249},\n",
    "    {\"name\": \"Kabul\", \"latitude\": 34.555349, \"longitude\": 69.207486},\n",
    "    {\"name\": \"Wunstorf\", \"latitude\": 52.4670, \"longitude\": 9.4330}            \n",
    "]\n",
    "\n",
    "# Function to get brightness for a given city and year\n",
    "def get_brightness(latitude, longitude, year):\n",
    "    # Load the VIIRS dataset for the specified year\n",
    "    start_date = f\"{year}-01-01\"\n",
    "    end_date = f\"{year}-12-31\"\n",
    "    viirs = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG\").filterDate(start_date, end_date)\n",
    "\n",
    "    # Get the mean image for the year\n",
    "    mean_image = viirs.mean()\n",
    "\n",
    "    # Create a point for the city location\n",
    "    point = ee.Geometry.Point([longitude, latitude])\n",
    "\n",
    "    # Sample the brightness value at the city location\n",
    "    brightness = mean_image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=point,\n",
    "        scale=500\n",
    "    ).get(\"avg_rad\")\n",
    "\n",
    "    return brightness.getInfo()\n",
    "\n",
    "# Extract brightness values for each city across multiple years\n",
    "years = [2012, 2017, 2023]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "for city in tqdm(cities, desc=\"Processing cities\"):\n",
    "    lat, lon = city['latitude'], city['longitude']\n",
    "    city_data = {\"City\": city[\"name\"]}\n",
    "    for year in years:\n",
    "        city_data[f'BI_{year}'] = get_brightness(lat, lon, year)\n",
    "    results.append(city_data)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate the brightness change per decade\n",
    "results_df['BI_change_decade'] = ((results_df['BI_2023'] - results_df['BI_2012']) / 11) * 10\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(results_df[['City', 'BI_2012', 'BI_2017', 'BI_2023', 'BI_change_decade']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadba6cf-2523-40fe-affd-340a28b80b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize the Earth Engine API (authentication required)\n",
    "# ee.Authenticate()\n",
    "# ee.Initialize()\n",
    "\n",
    "# Load metadata file with station information\n",
    "metadata_file = r'C:\\Users\\Administrator\\GHCN_stations_with_Landsat_GHSL_BU_1975to2020_metadata.csv'\n",
    "metadata_df = pd.read_csv(metadata_file)\n",
    "\n",
    "# Set batch size for processing\n",
    "batch_size = 50\n",
    "\n",
    "# Output file\n",
    "output_file = metadata_file.replace('.csv', '_BI.csv')\n",
    "\n",
    "# Do not delete the output file, continue from where it stopped\n",
    "processed_batches = 0  # Start from batch 453\n",
    "if os.path.exists(output_file):\n",
    "    print(f\"Resuming from batch {processed_batches + 1}\")\n",
    "\n",
    "# Function to get brightness for a given station and year\n",
    "def get_brightness(latitude, longitude, year):\n",
    "    # Load the VIIRS dataset for the specified year\n",
    "    start_date = f\"{year}-01-01\"\n",
    "    end_date = f\"{year}-12-31\"\n",
    "    viirs = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG\").filterDate(start_date, end_date)\n",
    "\n",
    "    # Get the mean image for the year\n",
    "    mean_image = viirs.mean()\n",
    "\n",
    "    # Create a point for the station location\n",
    "    point = ee.Geometry.Point([longitude, latitude])\n",
    "\n",
    "    # Sample the brightness value at the station location\n",
    "    brightness = mean_image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=point,\n",
    "        scale=1000\n",
    "    ).get(\"avg_rad\")\n",
    "\n",
    "    return brightness.getInfo()\n",
    "\n",
    "# Extract brightness values for each station across multiple years\n",
    "years = [2012, 2017, 2020, 2023]\n",
    "\n",
    "total_batches = (len(metadata_df) // batch_size) + (1 if len(metadata_df) % batch_size != 0 else 0)\n",
    "\n",
    "for batch_index in range(processed_batches, total_batches):\n",
    "    print(f\"Processing batch {batch_index + 1}/{total_batches}\")\n",
    "    start_idx = batch_index * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(metadata_df))\n",
    "    batch_df = metadata_df.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "    for index, row in batch_df.iterrows():\n",
    "        lat, lon = row['Lat'], row['Lon']\n",
    "        for year in years:\n",
    "            try:\n",
    "                brightness = get_brightness(lat, lon, year)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing station {row['Station_Name']} for year {year}: {e}\")\n",
    "                brightness = None\n",
    "            batch_df.at[index, f'BI_{year}'] = round(brightness, 2) if brightness is not None else brightness\n",
    "        time.sleep(0.01)  # Slight delay to avoid overwhelming Earth Engine servers\n",
    "\n",
    "    batch_df['BI_change_decade'] = batch_df.apply(\n",
    "        lambda x: round(((x['BI_2023'] - x['BI_2012']) / 11) * 10, 2) if pd.notnull(x['BI_2012']) and pd.notnull(x['BI_2023']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Write the updated batch DataFrame to the output CSV file\n",
    "    mode = 'a' if batch_index > 0 or processed_batches > 0 else 'w'\n",
    "    header = (batch_index == 0 and processed_batches == 0)\n",
    "    batch_df.to_csv(output_file, mode=mode, header=header, index=False)\n",
    "\n",
    "    # Update the main DataFrame with the batch results\n",
    "    metadata_df.update(batch_df)\n",
    "\n",
    "print(\"Batch processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0392ff9-9f2b-4812-9213-2e33ba251ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Load existing output file\n",
    "output_file = r'C:\\Users\\Administrator\\GHCN_stations_with_Landsat_GHSL_BU_1975to2020_metadata_BI.csv'\n",
    "if not os.path.exists(output_file):\n",
    "    raise FileNotFoundError(f\"The file {output_file} does not exist.\")\n",
    "\n",
    "result_df = pd.read_csv(output_file)\n",
    "\n",
    "# Remove duplicates based on 'ID'\n",
    "result_df = result_df.drop_duplicates(subset='ID', keep='last')\n",
    "\n",
    "# Perform linear least squares fit for each station ID\n",
    "bi_years = [2012, 2017, 2020, 2023]\n",
    "\n",
    "# Initialize new columns\n",
    "result_df['BI_2020_lsq'] = np.nan\n",
    "result_df['BI_trend_lsq'] = np.nan\n",
    "\n",
    "for index, row in result_df.iterrows():\n",
    "    bi_values = [row.get(f'BI_{year}', np.nan) for year in bi_years]\n",
    "    if all(pd.notnull(bi_values)):\n",
    "        slope, intercept, _, _, _ = linregress(bi_years, bi_values)\n",
    "        result_df.at[index, 'BI_2020_lsq'] = round(intercept + slope * 2020, 2)\n",
    "        result_df.at[index, 'BI_trend_lsq'] = round(slope, 2)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(result_df.head())\n",
    "\n",
    "# Optionally, write the updated DataFrame back to the CSV\n",
    "result_df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
