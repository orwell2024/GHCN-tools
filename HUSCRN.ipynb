{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c3c6e-e9f6-4709-ac61-5e8db90e5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educational Notebook : USCRN Legacy Pairs, GHCNv4 RAW. \n",
    "# 8 golden USCRN pairs used\n",
    "import requests\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import io\n",
    "\n",
    "# === Settings ===\n",
    "baseline_start = 1920\n",
    "baseline_end = 1940\n",
    "min_months = 11\n",
    "start_year = 1900\n",
    "end_year = 2024\n",
    "smoothing_frac = 0.13\n",
    "\n",
    "# === Step 1: Download and extract\n",
    "url = \"https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm.tavg.latest.qcu.tar.gz\"\n",
    "response = requests.get(url, stream=True)\n",
    "tar_bytes = io.BytesIO(response.content)\n",
    "\n",
    "# Station pairs, the magnificent 8 USCRN (HUSCRN) with more than 90 years data.\n",
    "pairs = [\n",
    "    (\"USC00012813\", \"USW00063869\"),\n",
    "    (\"USC00294426\", \"USW00003074\"),\n",
    "    (\"USC00402202\", \"USW00063855\"),\n",
    "    (\"USC00250030\", \"USW00094077\"),\n",
    "    (\"USC00018385\", \"USW00073801\"),\n",
    "    (\"USC00380764\", \"USW00063826\"),\n",
    "    (\"USC00013160\", \"USW00063892\"),\n",
    "    (\"USC00348501\", \"USW00053926\")\n",
    "]\n",
    "station_ids = {sid for p in pairs for sid in p}\n",
    "\n",
    "# === Step 2: Extract and grep lines\n",
    "filtered_lines = []\n",
    "with tarfile.open(fileobj=tar_bytes, mode=\"r:gz\") as tar:\n",
    "    dat_member = next(m for m in tar.getmembers() if m.name.endswith(\".qcu.dat\"))\n",
    "    dat_file = tar.extractfile(dat_member)\n",
    "    for line in dat_file:\n",
    "        sid = line[0:11].decode(\"utf-8\").strip()\n",
    "        if sid in station_ids and line[15:19].decode(\"utf-8\") == \"TAVG\":\n",
    "            filtered_lines.append(line.decode(\"utf-8\"))\n",
    "\n",
    "# === Step 3: Parse temperature data\n",
    "records = []\n",
    "for line in filtered_lines:\n",
    "    sid = line[0:11].strip()\n",
    "    year = int(line[11:15])\n",
    "    if year < start_year or year > end_year:\n",
    "        continue\n",
    "    monthly = [int(line[19 + m*8:24 + m*8]) for m in range(12)]\n",
    "    monthly = [v / 100.0 if v != -9999 else None for v in monthly]\n",
    "    if sum(v is not None for v in monthly) >= min_months:\n",
    "        avg = np.mean([v for v in monthly if v is not None])\n",
    "        records.append([year, avg, sid])\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\"year\", \"tavg\", \"station_id\"])\n",
    "\n",
    "# === Step 4: Build per-pair anomalies (with pairwise baseline subtraction)\n",
    "pairwise_anomalies = []\n",
    "\n",
    "for legacy_id, uscrn_id in pairs:\n",
    "    df_legacy = df[df[\"station_id\"] == legacy_id].set_index(\"year\")\n",
    "    df_uscrn = df[df[\"station_id\"] == uscrn_id].set_index(\"year\")\n",
    "    all_years = sorted(set(df_legacy.index).union(df_uscrn.index))\n",
    "    combined = []\n",
    "    for y in all_years:\n",
    "        temps = []\n",
    "        if y in df_legacy.index:\n",
    "            temps.append(df_legacy.loc[y, \"tavg\"])\n",
    "        if y in df_uscrn.index:\n",
    "            temps.append(df_uscrn.loc[y, \"tavg\"])\n",
    "        if temps:\n",
    "            combined.append([y, np.mean(temps)])\n",
    "    df_pair = pd.DataFrame(combined, columns=[\"year\", \"tavg\"])\n",
    "    \n",
    "    # Compute pair-specific baseline\n",
    "    base = df_pair[(df_pair[\"year\"] >= baseline_start) & (df_pair[\"year\"] <= baseline_end)]\n",
    "    if not base.empty:\n",
    "        baseline_mean = base[\"tavg\"].mean()\n",
    "        df_pair[\"anomaly\"] = df_pair[\"tavg\"] - baseline_mean\n",
    "        pairwise_anomalies.append(df_pair[[\"year\", \"anomaly\"]])\n",
    "\n",
    "# === Step 5: Aggregate anomalies across all pairs (after baseline subtraction)\n",
    "df_all = pd.concat(pairwise_anomalies)\n",
    "df_agg = df_all.groupby(\"year\")[\"anomaly\"].mean().reset_index()\n",
    "\n",
    "# === Step 6: LOESS smoothing\n",
    "loess = sm.nonparametric.lowess(endog=df_agg[\"anomaly\"],\n",
    "                                exog=df_agg[\"year\"], frac=smoothing_frac)\n",
    "\n",
    "# === Step 7: Plot (dark background, styled)\n",
    "plt.style.use('dark_background')\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(df_agg[\"year\"], df_agg[\"anomaly\"], label=\"Aggregated Anomaly\", color='cyan',\n",
    "        linewidth=2, marker='o', markersize=4, alpha=0.9)\n",
    "ax.plot(loess[:, 0], loess[:, 1], color='cyan', linewidth=4, alpha=0.6, label=\"LOESS Trend\")\n",
    "\n",
    "ax.set_title(\"Historic USCRN Temperature Anomalies (Baseline 1920–1940) – GHCN RAW\", fontsize=15, weight='bold')\n",
    "ax.set_xlabel(\"Year\", fontsize=12)\n",
    "ax.set_ylabel(\"Temperature Anomaly (°C)\", fontsize=12)\n",
    "ax.set_ylim(-2, 3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"upper left\", fontsize=10)\n",
    "\n",
    "fig.text(0.01, -0.12,\n",
    "         \"Data Source: GHCN v4.0.1 QCU – NOAA\\n\"\n",
    "         \"Yearly averages computed from >=11 months per year.\\n\"\n",
    "         \"Anomalies computed per station pair using 1920–1940 baseline.\\n\"\n",
    "         \"Then averaged across all 8 pairs.\\n\",\n",
    "         fontsize=9, color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
